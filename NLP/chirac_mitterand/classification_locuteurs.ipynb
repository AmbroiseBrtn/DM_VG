{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de locuteur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objectif : créer une chaine de traitement des données textuelles sur la classification de locuteur\n",
    "\n",
    "#### Jeu de données : citations Chirac Mitterand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analyses obligatoires\n",
    "    * Comparer les performances avec différents pré-traitements\n",
    "        * e.g Taille de vocabulaire, unigram/bigram, Stemming, ...\n",
    "    * Implémenter un post-traitement sur les données Chirac/Mitterrand\n",
    "    * Appliquer les traitements optimaux sur les données de test et sauver les résultats dans un fichier txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compléments optionnels\n",
    "    * Analyser les performances avec Word2Vec, en utilisant des stratégies d'agrégation naïves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ecrire un rapport succinct\n",
    "    * Présentant les courbes de performances pour les paramètres les plus influents/marquants\n",
    "    * Quelques conclusions sur le travail effectué"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Soumettre par mail:\n",
    "    * Rapport, Notebook(s), 2 fichiers de scores (locuteur/opinion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données Mitterand / Chirac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données:\n",
    "def load_pres(fname):\n",
    "    alltxts = []\n",
    "    alllabs = []\n",
    "    s=codecs.open(fname, 'r','utf-8') # pour régler le codage\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        #\n",
    "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
    "        if lab.count('M') >0:\n",
    "            alllabs.append(-1)\n",
    "        else: \n",
    "            alllabs.append(1)\n",
    "        alltxts.append(txt)\n",
    "    return alltxts,alllabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/AFDpresidentutf8/corpus.tache1.learn.utf8\"\n",
    "\n",
    "alltxts,alllabs = load_pres(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification de l'équilibre du plan d'expérience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 86.89669587027329 % de citations attribuées à Mitterand et 13.103304129726718 % de citations attribuées à Chirac \n"
     ]
    }
   ],
   "source": [
    "C, M = np.unique(alllabs, return_counts=True)[1]\n",
    "print(f\"Il y a {M/(C+M) * 100} % de citations attribuées à Mitterand et {C/(C+M) * 100} % de citations attribuées à Chirac \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que le plan d'expérience n'est pas équilibré. Il va falloir échantilloner notre dataset pour se ramener à une situation à l'équilibre (50% des exemples associés à chaque locuteur)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under-sampling dans la classe majoritaire 'Mitterand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Instancier le RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy='auto')  # 'auto' signifie que la stratégie est de rééquilibrer toutes les classes à la taille de la classe minoritaire.\n",
    "\n",
    "# Appliquer la méthode fit_resample\n",
    "alltxts_res, alllabs_res = rus.fit_resample(np.array(alltxts).reshape(-1, 1), alllabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 50.0 % de citations attribuées à Mitterand et 50.0 % de citations attribuées à Chirac \n"
     ]
    }
   ],
   "source": [
    "C, M = np.unique(alllabs_res, return_counts=True)[1]\n",
    "print(f\"Il y a {M/(C+M) * 100} % de citations attribuées à Mitterand et {C/(C+M) * 100} % de citations attribuées à Chirac \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'under sampling a permis le réequilibrage des classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On réassigne les variables pour plus de clarté dans le code\n",
    "alltxts, alllabs = alltxts_res, alllabs_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des mots fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ambroisebertin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ambroisebertin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 36791\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk import bigrams, trigrams, FreqDist, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Nécessaire pour la première exécution\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "all_texts, all_labels = load_pres(path)\n",
    "\n",
    "text = \" \".join([str(elem) for elem in all_texts])\n",
    "\n",
    "# Retire la ponctuation\n",
    "translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "text = text.translate(translator)\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Filtre les stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "tokens = list(filter(lambda token: token not in stop_words, tokens))\n",
    "\n",
    "freq_dist = FreqDist(tokens)\n",
    "vocab_size = len(freq_dist)\n",
    "print(f\"Taille du vocabulaire : {vocab_size}\")\n",
    "\n",
    "# Calcule les 100 bigrammes et trigrammes les plus fréquents\n",
    "bigrams = list(bigrams(tokens))\n",
    "trigrams = list(trigrams(tokens))\n",
    "\n",
    "bigram_freq = FreqDist(bigrams)\n",
    "trigram_freq = FreqDist(trigrams)\n",
    "\n",
    "top_100_bigrams = bigram_freq.most_common(100)\n",
    "top_100_trigrams = trigram_freq.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "freq_dist.plot(100)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "bigram_freq.plot(100)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "trigram_freq.plot(100)\n",
    "plt.show()\n",
    "\n",
    "# NB : modifier le code pour qu'il sauvegarde les figures dans un dossier \"figures\" (créé au préalable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 45930\n",
      "Taille de l'ensemble de test : 11483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "alltxts, alllabs = load_pres(path)\n",
    "\n",
    "# Diviser le dataset\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(all_texts, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Taille de l'ensemble d'entraînement :\", len(train_texts))\n",
    "print(\"Taille de l'ensemble de test :\", len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision : 0.8965427153182967\n"
     ]
    }
   ],
   "source": [
    "# Appliquer la classification naïve bayésienne\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Créer le vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Vectoriser les données d'entraînement\n",
    "train_vectors = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Vectoriser les données de test\n",
    "test_vectors = vectorizer.transform(test_texts)\n",
    "\n",
    "# Créer le classifieur\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Entraîner le classifieur\n",
    "clf.fit(train_vectors, train_labels)\n",
    "\n",
    "# Prédire les labels des données de test\n",
    "pred = clf.predict(test_vectors)\n",
    "\n",
    "# Calculer la précision\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"Précision : {accuracy_score(test_labels, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
